---
title: NGINX One Console Lab - Adding NGINX Instances to NGINX One
description: Getting console access, starting the lab
order: 7
---

## What is NGINX One?

NGINX One is an all-in-one platform that integrates the best of NGINX’s offerings into a unified package that includes a cloud-based dashboard and access to [F5 Distributed Cloud](https://www.f5.com/cloud). Customers get advanced load balancing, web and application server capabilities, API gateway functionalities, and security features. The goal of NGINX One is to provide unparalleled performance, security, and scalability for modern applications, whether they are deployed in the cloud, on-premises, or in hybrid environments.

## NGINX One Console

NGINX One Console gives all NGINX users access to a SaaS experience for managing NGINX instances as part of the F5 Distributed Cloud. It gives NGINX users unrivaled visibility, delivery and optimization capabilities combined with the speed and flexibility of the F5 Distributed Cloud Platform.

The NGINX One Console is valuable because it simplifies the complexities of modern application delivery by integrating multiple functionalities into a single platform. This reduces the need for disparate tools, lowers operational overhead and costs, and ensures robust security for your applications. Additionally, its comprehensive feature set—including advanced load balancing, enhanced security, and performance optimization—provides customers with a reliable, scalable, and secure solution for managing their applications.

You will be able to accelerate application delivery and time-to-value like never before with flexible pricing and SaaS capabilities.

With NGINX One Console, you will get improved:

- Performance at scale
- Visibility and insight
- Security and control

## Lab Introduction

This lab will give you an overview of how the NGINX One console provides visibility into a global fleet of NGINX instances, both NGINX Plus and NGINX Open Source (OSS).

After this lab, you will be able to:

- Access and navigate the NGINX One console
- Manage NGINX configuration
- Review recommendations from the NGINX One console
- Install the NGINX Agent on both NGINX Plus and NGINX OSS instances

## Prerequisites

The "NGINX One Enablement Lab" UDF blueprint contains all the prerequisites for this lab. This includes:

- This interactive lab guide
- NGINX Plus and NGINX OSS instances
- F5 XC [lab tenant](https://f5-xc-lab-app.console.ves.volterra.io) access

> Tip: Clicking on any image in this lab guide lab will enlarge it. To dismiss the enlarged image, click the white "X" in its window, or press the Escape key.

## F5 Distributed Cloud Tenant Access

Once you join the UDF session, your UDF deployment will start and create an ephemeral account on the F5 Distributed Cloud console (this may take 5-10min).

1. Once your ephemeral account is created, you will receive an email to set or update your password. Click the **Update Password** link in the email. Check the spam folder for the account used to register with UDF if you can't find the email.

    ![XC Console Email](media/lab0-01.png)

1. Update your password. Click **Submit**.

    ![image](media/lab0-02.png)

1. Click **Log In**.

    ![image](media/lab0-03.png)

1. Once redirected to the F5 Distributed Cloud console login, enter the lab tenant name (*f5-xc-lab-app*), and click **Next**. Enter your email and password and click **Sign in**.

    ![image](media/lab0-11.png)
    ![image](media/lab0-10.png)

1. Check the radio box and click **Accept and Agree** after reviewing terms.

    ![image](media/lab0-05.png)

1. F5 XC console "persona" and the "skill level" settings dictate how services and configuration options are presented to the user. These settings are currently not applicable to the NGINX One console. Make any valid selection for each dialog. Click **Next** or **Get Started** depending on the dialog.

    ![image](media/lab0-06.png)

    ![image](media/lab0-07.png)

1. Several **Guidance ToolTips** might appear. These are used to inform users of new features when the F5 XC console is updated. Close the dialogues and continue.

## Accessing NGINX One Console

Once logged into the F5 XC console, the "home" screen shows you various tiles which represent console features. For example, you might configure Multicloud networking from the "Multi-Cloud Network Connect" tile, build global server load balancing rules from the "DNS Management" tile, or view synthetic monitoring data from the "Observability" tile. In this lab, we'll focus on the Nginx One console.

> :point_right: **Note:** Your permissions in the F5 XC console are specific to this lab. You don't have permissions to all the tiles on the "home" screen.

1. Click the **NGINX One** tile from the home screen.

    ![NGINX One in the XC Console](media/lab1-1.png)

1. The NGINX One "welcome" screen will appear. Click **Visit Service** to proceed to the NGINX One console.

    ![The NGINX One Welcome Screen](media/lab1-2.png)

1. The NGINX One Dashboard shows an overview of your environment, including availability, platform and version distribution, and CVEs/configuration recommendations. Your dashboard will vary depending on what is installed in your tenant. Feel free to click around and explore.

    ![NGINX One Dashboard](media/lab1-3.png)

1. In the left-hand menu in the *Manage* section is the *Instances* link. You may or may not have any existing instances in your tenant. Don’t worry if there aren’t any, you will be deploying two instances later in the lab. If there are any existing instances, click an instance’s hostname to view its details.

    ![NGINX One instance details](media/lab1-4.png)

## Connecting to the Console

NGINX One uses an agent installed alongside NGINX to communicate with the NGINX One service.

![There are two instances in the customer environment: one Plus and one OSS. An additional NGINX Agent is installed alongside NGINX in each instance, and the Agent communicates between the NGINX instance and the NGINX One service.](media/lab2-1.png)

The agent uses a Data Plane Key to authenticate and identify itself to NGINX One. In this lab we will create a new Data Plane Key, and use it to install the NGINX Agent on the NGINX Plus instance.

### Generating a Data Plane Key

1. From the NGINX One console, in the left hand menu under the "Manage" section, select **Data Plane Keys**.

1. Click **Add Data Plane Key**.

1. Give the key a name based on your lab's ephemeral name, such as **<GetVariable name="petname" />-nginx-key**.

    > :point_right: **Note:** You are working in a shared environment; keep track of your resources, and be careful not to accidentally modify anyone else's.

1. By default, the key expiration date will be set to 1 year.  Depending on your use case, you may want to set a shorter expiration date.  For this lab, we will use the default value.

1. Click **Generate**.

    ![Generating a Data Plane Key](media/lab2-4.png)

1. The Data Plane Key will be displayed. Click the *Copy* icon to copy the key to the clipboard.

    > :warning: **Warning:** *SAVE THIS KEY SOMEWHERE SAFE.* There is no way to retrieve the key after you click **close**. This key will be used in multiple labs.

    ![Data Plane Key](media/lab2-5.png)

## NGINX OSS

The NGINX One Console supports both NGINX Plus and NGINX OSS. Both products leverage the NGINX Agent to communicate with the NGINX One Console API.
The UDF blueprint contains a Ubuntu host with the package maintainer’s version of NGINX OSS installed.  In this section we will install NGINX Agent and connect this instance to the NGINX One Console.

### Installing NGINX Agent on NGINX OSS

1. Connect to the "NGINX OSS" instance in UDF through the Web Shell access method by clicking the *Open Web Shell* button below:

1. Because the hostname is used as the name of the instance in NGINX One, you should change the hostname to something that identifies it as yours, such as **<GetVariable name="petname" />-ubuntu-oss**.
Ensure that you are working on the NGINX OSS instance (default hostname ip-10.1.1.6), and run the following command below using only lowercase characters and hyphens.

    > **Note:** The bash prompt will continue to show the previous hostname unless you log out and log back in. This does not affect the lab.

        ```bash
        sudo hostnamectl set-hostname {{petname}}-ubuntu-oss
        ```

1. From the NGINX OSS instance, run the following command to install the NGINX Agent. Substitute data-plane-key with the key you saved in the first lab. Make sure you are working on the NGINX OSS instance; if you accidentally install on the jumphost, the installation will succeed, but there will be no NGINX instance for the agent to connect to and the instance will appear as "Offline". If this occurs, return to the directions in lab 1 to create a new Data Plane Key.

        ```bash
        curl https://agent.connect.nginx.com/nginx-agent/install | DATA_PLANE_KEY='data-plane-key' sh -s -- -y
        ```

    The install script will install any necessary dependencies, and install the NGINX Agent with the appropriate settings for your system. You will see a warning about "stub_status" not being configured. You can ignore that warning.

### Viewing Logs

Now let's take a look at the NGINX agent logs. The logs can be found in /var/log/nginx-agent.

1. Start an interactive Bash shell session inside the specified container

    ``` bash
    docker exec -it YOUR_CONTAINER_ID /bin/bash
    ```

1. Use the following command to view the NGINX Agent logs in real time.

    ``` bash
    tail -f /var/log/nginx-agent/agent.log
    ```


1. Return to the NGINX One console. From the left menu in the *Manage* section, click *Instances*. You should see your new instance in the list.

1. Click its hostname to view the instance details.

    ![Instance list](media/optional1-1.png)

1. Explore the instance details.

    ![Instance Details](media/optional1-2.png)

    Note that this instance has a different set of configuration recommendations than the vanilla NGINX Plus instance did. Package maintainers may ship NGINX with their own sets of defaults, which may or may not align with best practices. NGINX One provides a centralized view of such recommendations across the organization.

### Viewing Logs

Now let's take a look at the NGINX agent logs. The logs can be found in /var/log/nginx-agent. Use the following command to view the NGINX Agent logs in real time.

1. Connect to the "NGINX OSS" instance in UDF through the Web Shell access method. 

    ``` bash
    tail -f /var/log/nginx-agent/agent.log
    ```

## NGINX Docker

The **Lab Framework** from the UDF environment has **docker** installed and is setup so it can run an NGINX Plus container image. The container image we will use here is **private-registry.nginx.com/nginx-plus/agent:debian** which has NGINX Plus with the Agent. If you want to see a list of all NGINX Plus with Agent tags, refer to the [documentation](https://docs.nginx.com/nginx/admin-guide/installing-nginx/installing-nginx-docker/#pulling-the-image).

1. Go to *Instances* under *Manage* and click *Add Instance*.

1. If you saved your Data Plane Key from a previous lab, select *Use existing Key*. Otherwise select *Generate new key*.

1. Provide your Data Plane Key if you selected *Use existing Key*.

1. Select the *Docker Container* tab.

    ![Add New NGINX Plus Container](media/lab5-17.png)

    > **Note:** This system already cached the container image, so Steps 1 and 2 from above can be skipped.

1. Open a Web Shell to the **Lab Framework** UDF instance and start an NGINX Plus container with the commands below.

1. Run the *docker run* command outlined in Step 3 to start the NGINX Plus with Agent container. Start the Docker container. Replace YOUR_DATA_PLANE_KEY with your actual NGINX One data plane key and VERSION_TAG with the specific version tag you pulled.

        ```shell

    sudo docker run --hostname=YOUR_HOSTNAME --name=YOUR_CONTAINER_NAME \
    --env=NGINX_AGENT_SERVER_GRPCPORT=443 \
    --env=NGINX_AGENT_SERVER_HOST=agent.connect.nginx.com \
    --env=NGINX_AGENT_SERVER_TOKEN=YOUR_DATA_PLANE_KEY \
    --env=NGINX_AGENT_TLS_ENABLE=true \
    --env=NGINX_AGENT_TLS_SKIP_VERIFY=false \
    --restart=always \
    --runtime=runc \
    -d private-registry.nginx.com/nginx-plus/agent:VERSION_TAG
        ```

1. Click *Done* to close the window.

1. Return to the NGINX One console. From the left menu in the Manage section, click Instances. You should see your new instance in the list.


### Viewing Logs

Now let's take a look at the NGINX agent logs. The logs can be examined by connecting to the container.

1. Start an interactive Bash shell session inside the specified container

    ``` bash
    docker exec -it YOUR_CONTAINER_ID /bin/bash
    ```

1. Use the following command to view the NGINX Agent logs in real time.

    ``` bash
    tail -f /var/log/nginx-agent/agent.log
    ```


## Console Overview

Now that we have set up our data plane key and deployed our NGINX instances we can take a look around the NGINX One Console:

1. Return to the NGINX One Console. From the left menu in the *Manage* section, click *Instances*.

1. You should see your **<GetVariable name="nginx-plus-1" />** instance in the list, click on it to view the instance details.

    ![NGINX One Instance List](media/lab2-7.png)

### Explore the instance details

The NGINX One Console provides several key metrics for us to evaluate:

    - Instance Certificates
    - Instance CVEs
    - Configuration Recommendations
    - Instance Details

    ![NGINX Plus instance details](media/lab2-8.png)

#### Instance Certificates

The NGINX One Console displays the number of certificates currently installed on the NGINX instance as well as the current status of the certificates, expiration date,
and the certificate's *Subject Name*.

We'll get to explore this in greater detail later in the lab when we install a SSL/TLS certificate.

#### Instance CVEs

The NGINX One Console displays the number of CVEs associated with the NGINX instance as well as their severity.  You can also find out more information about each CVE
with a link to the CVE Program website with extensive details about the CVE in question.

#### Configuration Recommendations

The NGINX One Console will evaluate the NGINX instance configuration and provide recommendations based on best practices and security concerns.
We'll get to explore this in greater detail later in the lab when we configure the stub_status location.

#### Instance Details

The NGINX One Console also provides various details about the NGINX instance such as:

    | Instance Type | Description |
    | --- | --- |
    | Availability | The availability status of the NGINX instance |
    | Data Plane Key | The data plane key associated with the NGINX instance |
    | Hostname | The hostname of the NGINX instance |
    | Last Seen | The last time the NGINX instance was seen |
    | NGINX Agent Version | The version of the NGINX Agent running on the instance |
    | NGINX Config Path | The path to the NGINX configuration file |
    | Operating System | The operating system running on the instance |
    | Registration Time | The time when the NGINX instance was registered |
    | Instance Type | The type of the NGINX instance |

### Explore NGINX One dashboard

The NGINX One Dashboard provides an at-a-glance view of metrics and findings about your global NGINX fleet.

You can navigate to the NGINX One Dashboard view by selecting *Dashboard* under the *Overview* section on the left.

![Dashboard Side Menu](media/lab1-5.png)

You now see a Dashboard view like the example shown below.

![Dashboard View](media/lab1-6.png)

This view provides the following metrics for all NGINX instances.

    | Metric Type | Description |
    | --- | --- |
    | Availability | The overall reachability and availability of your NGINX fleet is displayed here. |
    | NGINX Versions | We can see at a glance what proportion of our fleet is running Plus vs. OSS, and how many instances are running outdated or non-standard versions. |
    | OS Distribution | Similarly, we can see which OSes are part of the fleet. |
    | Certificates | This chart provides insight on expiring certificates that need attention, as well as expired ones that should be removed. |
    | Configuration Recommendations | NGINX One analyzes the configuration files on all of the instances it manages. When a configuration presents a potential security risk or is otherwise not in accordance with best practices, a recommendation is shown. |
    | CVEs | Any CVEs that apply to an instance in your fleet are shown here. |
    | CPU Utilization | The instances with the highest CPU Utilization are shown here for quick visibility into potential performance issues. |
    | Memory Utilization | Top memory consumers are also shown here. |
    | Disk Space Utilization | Along with CPU and memory, instances with the highest disk utilization are shown here to surface possible disk space issues. |
    | Unsuccessful Responses | Instances with the most 4xx or 5xx errors appear here to identify potential attacks, misconfigurations, or upstream application issues. |
    | Network Usage | Top network consumers can help identify targets for optimization. Unusual traffic patterns could potentially indicate an attack attempt. |

**Drilling Down**

Clicking a detail line in any of these charts will let you drill-down and see the instances affected by that particular finding.

![NGINX Drilling Down View](media/lab1-7.png)

---

## Configuration via the Console

In this section, we will leverage NGINX One Console to enable the [stub_status](https://nginx.org/en/docs/http/ngx_http_stub_status_module.html?_ga=2.62776364.1844058681.1724599557-1323320886.1720986347)
location in our **<GetVariable name="nginx-plus-1" />** NGINX instance's configuration.

The stub_status allows users to collect basic metrics about the NGINX instance such as:

- Active connections
- Total number of accepted client connections
- Total number of client requests
- and many more

### Adding a stub_status directive

1. In the NGINX One console, select *Manage* and then *Instances* from the left menu.

1. You should see your **<GetVariable name="nginx-plus-1" />** instance in the list. Click it to view the instance details.

1. Click the *Configuration* link near the top of the instance screen. You will be presented with the configuration editor.

    ![Configuration link](media/lab3-1.png)


#### NGINX Configuration

Now let's take a look at what the **/etc/nginx/nginx.conf** configuration is doing:

    ```nginx
    user  nginx;
    worker_processes  auto;

    error_log  /var/log/nginx/error.log notice;
    pid        /var/run/nginx.pid;

    events {
        worker_connections  1024;
    }
    ```

Let's break down this portion of the NGINX configuration:

**1. *user  nginx;***

This line specifies the user under which NGINX will run as a process. In this case, it's running as the *nginx* user. This is important for security and permission reasons.

When NGINX starts, it needs to bind to certain system resources (e.g., network sockets). By specifying a specific user, we ensure that any processes started by NGINX will run with minimal privileges, reducing the risk of unauthorized access or resource consumption.

**2. worker_processes  auto;**

This line configures how many worker processes NGINX will create to handle incoming requests. The value is set to *auto*, which means that NGINX will automatically determine the optimal number of workers based on the system's capabilities and load.

The *auto* value tells NGINX to:

    * On systems with multiple CPU cores, create a worker process for each core.
    * On systems with a single CPU core, use the system's default maximum process limit (usually 1024).
    * Consider other factors like memory availability and load when deciding on the optimal number of workers.

**3. error_log  /var/log/nginx/error.log notice;**

This line configures how NGINX logs errors that occur during execution. The *notice* level is set, which means that:

    * Errors with a severity level greater than or equal to NOTICE will be logged.
    * Other error levels (e.g., ERROR, WARNING) won't be logged.

The log file location */var/log/nginx/error.log* indicates where NGINX will write its error messages. This is the standard log location for most Linux distributions.

**4. pid /var/run/nginx.pid;**

This line specifies the file path where NGINX will store its process ID (PID). The PID is a unique identifier that allows you to manage and monitor running processes on your system.

In this case, the PID is written to */var/run/nginx.pid*, which is a common location for Linux services like NGINX.

**5. worker_connections 1024;**

This line specifies the maximum number of simultaneous connections a worker process can handle. In this case, it's set to 1024, which means each worker process will be able to accept up to 1024 simultaneous client connections.

    ```nginx
    http {
        include       /etc/nginx/mime.types;
        default_type  application/octet-stream;

        log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
                        '$status $body_bytes_sent "$http_referer" '
                        '"$http_user_agent" "$http_x_forwarded_for"';

        access_log  /var/log/nginx/access.log  main;

        sendfile        on;
        #tcp_nopush     on;

        keepalive_timeout  65;

        #gzip  on;

        include /etc/nginx/conf.d/*.conf;
    }
    ```

Here's a brief explanation of this portion of the NGINX configuration:

**HTTP Block**

This block configures how NGINX handles HTTP requests.

**1. include /etc/nginx/mime.types;**

Includes the MIME types file, which maps file extensions to their corresponding content types.

**2. default_type application/octet-stream;**

Specifies the default response type for unknown content types.

**3. log_format main ...**

Defines a custom log format called "main", which logs various request details (e.g., client IP, user agent).

**4. access_log /var/log/nginx/access.log main;**

Enables access logging to the specified file using the defined log format.

**5. sendfile on;**

Enables the sendfile() method for sending files directly from disk to clients, improving performance.

**6. keepalive_timeout 65;**

Sets the keep-alive timeout to 65 seconds, allowing NGINX to maintain connections with clients for a longer period.

**7. include /etc/nginx/conf.d/*.conf;**

Includes all configuration files in the specified directory (e.g., virtual hosts).

Now lets take a look at what the **/etc/nginx/conf.d/default.conf** configuration is doing:

    ```nginx
    server {
        listen       80 default_server;
        server_name  localhost;

        #access_log  /var/log/nginx/host.access.log  main;

        location / {
            root   /usr/share/nginx/html;
            index  index.html index.htm;
        }

        #error_page  404              /404.html;

        # redirect server error pages to the static page /50x.html
        #
        error_page   500 502 503 504  /50x.html;
        location = /50x.html {
            root   /usr/share/nginx/html;
        }
    }
    ```

Here's a brief overview of this NGINX configuration:

**Server Block**

This block configures a single server that listens on port 80 and responds to requests for the domain *localhost*.

- *listen 80 default_server;* specifies that this server should listen on port 80 by default.
- *server_name localhost;* indicates that this server will respond to requests from the domain *localhost*.

**Root Directory and Indexing**

The configuration sets up a single location block that serves files from the */usr/share/nginx/html* directory:

- *root /usr/share/nginx/html;* specifies the root directory for this location.
- *index index.html index.htm;* specifies the default index file to serve when no specific file is requested (in this case, either *index.html* or *index.htm*).

**Error Handling**

The configuration also sets up error handling:

- *error_page 500 502 503 504 /50x.html;* specifies that if any of these specific HTTP errors occur, the client should be redirected to the static page */50x.html*.
- *location = /50x.html* specifies where NGINX can find the error page file.

#### Edit the NGINX Configuration

1. Click the *Edit Configuration* button above the editor.

    ![Edit Configuration link](media/lab3-2.png)

1. Select the **/etc/nginx/conf.d/default.conf** file from the tree view on the left side of the configuration editor.

    ![Select default.conf file](media/lab3-3.png)

1. Edit the selected file to include a location block at the end of the server block with
    the **stub_status** directive. Add the following location block to the server block:

        ```nginx
            location = /nginx_status {
                stub_status;
            }
        ```

    The file should like this (commented out configurations have been removed):

        ```nginx
        server {
            listen       80 default_server;
            server_name  localhost;

            #access_log  /var/log/nginx/host.access.log  main;

            location / {
                root   /usr/share/nginx/html;
                index  index.html index.htm;
            }

            #error_page  404              /404.html;

            # redirect server error pages to the static page /50x.html
            #
            error_page   500 502 503 504  /50x.html;
            location = /50x.html {
                root   /usr/share/nginx/html;
            }

            location = /nginx_status {
                stub_status;
                access_log off;
            }
        }
        ```

1. You will see that there is a message below the editor:

    > *1 recommendation found for /etc/nginx/conf.d/default.conf <br />
        Security - Error: stub_status should have access control list defined*.

    - **Why?** NGINX One includes a configuration advisor and it identified that exposing the **stub_status** endpoint open to the world is considered a security risk.
    - We can remediate this by adding an ACL to the **/nginx_status** location block to only allow our lab environments's local networks and NGINX Agent (running locally on the instance) to access the stub status endpoint.

    ![config warning](media/lab3-4.png)

1. Update that section of the configuration to the following:

        ```nginx
            location /nginx_status {
                stub_status;
                allow 10.0.0.0/8;
                allow 172.18.0.0/16;
                allow 127.0.0.1;
                deny all;
            }
        ```

    Note that the warning should disappear.

1. Click *Next* to display the diff viewer. This view will show you the changes made to the configuration.

    ![Diff viewer](media/lab3-5.png)

1. Click *Save and Publish*. You will see a status message indicating changes are being published, followed by a success message after several seconds.

    ![Publish config pending](media/lab3-6.png)

    ![Publish config success](media/lab3-7.png)

1. Check that the *stub_status* module is working by clicking the *Check* button below.

    <APICheck
        componentName="nginx-plus-1"
        path="/nginx_status"
        targetStatusCode={200}
    />

### Using a TLS certificate

In this section, we will configure our **<GetVariable name="nginx-plus-1" />** NGINX instance to leverage an SSL/TLS certificate.

1. In the NGINX One Console, edit the **/etc/nginx/conf.d/default.conf** file again on the **<GetVariable name="nginx-plus-1" />** instance. Add the following to the server block:

        ```nginx
            listen 443 ssl;
            ssl_certificate /etc/nginx/ssl/wildcard.f5demos.com.crt.pem;
            ssl_certificate_key /etc/nginx/ssl/wildcard.f5demos.com.key.pem;
        ```

1. Click *Next* to display the diff viewer. This view will show you the changes made to the configuration.

    ![Diff viewer](media/lab3-9.png)

1. Click *Save and Publish*. You will see a status message indicating changes are being published, followed by a success message after several seconds.

1. Click the *Details* link on the page. You should now see the certificate, its validity status, expiration date, and subject name.

    ![Details link](media/lab3-10.png)

1. The *details* page will also show a new recommendation. You can view the configuration, and recommendations by clicking the *View Configuration* link in the *Configuration Recommendations* section.

    ![Certificate status](media/lab3-11.png)

1. Select the *default.conf* file from the file picker. Note the blue dots and the number "1" next to default.conf; the configuration viewer highlights the location(s) of any recommendations it has for the NGINX configuration.

    ![Configuration Viewer](media/lab3-12.png)

1. Notice the editor has a "Best Practice" notice indicating that *default_server* should set. Update the configuration to acknowledge this recommendation. <br />&nbsp;<br />The entire **/etc/nginx/conf.d/default.conf** file should now look as follows (commented out configurations have been removed):

        ```nginx
        server {
            listen       80 default_server;
            server_name  localhost;

            listen 443 ssl default_server;
            ssl_certificate /etc/nginx/ssl/wildcard.f5demos.com.crt.pem;
            ssl_certificate_key /etc/nginx/ssl/wildcard.f5demos.com.key.pem;

            #access_log  /var/log/nginx/host.access.log  main;

            location / {
                root   /usr/share/nginx/html;
                index  index.html index.htm;
            }

            #error_page  404              /404.html;

            # redirect server error pages to the static page /50x.html
            #
            error_page   500 502 503 504  /50x.html;
            location = /50x.html {
                root   /usr/share/nginx/html;
            }

            location /nginx_status {
                stub_status;
                allow 10.0.0.0/8;
                allow 172.18.0.0/16;
                allow 127.0.0.1;
                deny all;
            }
        }
        ```

1. Check your work:<br />&nbsp;<br />To check that the <GetVariable name="nginx-plus-1" /> instance is now listening on 443 click the *Check* button below.

    <APICheck
        componentName="nginx-plus-1"
        targetStatusCode={200}
        tlsComponent={true}
    />

## Lab Cleanup

Time to clean up the resources you created in this lab. As a safety precaution, the NGINX One console will not allow you to delete an instance that is online. We will first have to shut down the instances before deleting them from the NGINX One console.


1. For the Docker containers running NGINX run the commands below to stop and remove the container from the NGINX Plus instance in your UDF deployment.

    ``` docker
    docker stop YOUR_CONTAINER_ID
    docker rm YOUR_CONTAINER_ID
    ```

1. In the UDF deployment for this lab, click *Details* for the **NGINX OSS** component.

    ![Select the NGINX component details](media/cleanup-1.png)

1. Click the **Stop** button for this component.

    ![Select the NGINX component details](media/cleanup-2.png)

    > **Note:** You can also remove the nginx-agent running on the NGINX OSS instance using the commands below.

    ```nginx
    sudo apt-get purge nginx-agent
    sudo apt-get autoremove
    sudo apt-get update
    ```

1. From the NGINX One console, in the left-hand menu in the *Manage* section, select *Instances*.

1. Wait until your **<GetVariable name="petname" />*** instances transition into the **Unavailable** state before proceeding. You may need to click the *Refresh* button at the top right of the instance list.

    ![Instance Unavailable](media/cleanup-3.png)

1. For each of your **<GetVariable name="petname" />*** instances, select the *Actions* "..." context menu, and select
    *Delete*.

    > :warning: **Warning:** Make sure you are deleting your own instances and not someone else’s.

    ![Deleting an instance](media/cleanup-4.png)

1. Confirm the deletion.

    ![Confirming the deletion](media/cleanup-5.png)

1. From the NGINX One console, in the left-hand menu in the *Manage* section, select *Data Plane Keys*.

1. Select the context menu for the Data Plane Key you created in lab 1, and select *Revoke*.

    > :warning: **Warning:** Make sure you are revoking your own key and not someone else’s.

    ![Revoking a Data Plane Key](media/cleanup-6.png)

1. Confirm the revocation.

    ![Confirming the revocation](media/cleanup-7.png)
